Discovery:
  Team decided that we wanted to build something to serve the public, something that would be meaningful and understandable by an average citizen. Strawman user scenarios were written.
  
  <insert screen cap of user scenarios>
  
  Several technical team members and subject-matter experts with historical knowledge of EPA data reviewed available data to understand its characteristics, context and presentation against user scenarios. The team pulled together an initial list of data for consideration:
  
  <insert screen cap of justin's email>
  
  Our UX team also conducted several user interviews to validate our assumptions about the value of building a tool that could serve up the type of data we had identified. 
  
  <insert screen cap of raw interview notes>
  
Visioning: 
The team began by developing a "Vision Canvas," a single document meant to articulate the "elevator pitch" for the product: Who uses it? What is its value? What problems is it solving? How will we measure success?

<insert vision canvas screen cap here>

The Vision Canvas articulated exactly what type of users we would target with the first release of our product, and what value the product would bring those users. From there, we defined two personas; Personas were used to ensure we considered all contexts of use and identified the most critical features to build first to best serve user needs. 

<insert persona screen caps>

Co-development: 
Our product manager, UX designer and developer collaborated in real-time via Skype, Webex, phone and Facetime to deliver elements of a working product as quickly as possible. We created little documentation, instead using hand-drawings, balsamiq wireframes, and real-time development to execute faster. Our developer used an existing framework to stand up the product quickly--it looked great "out of the box" and more importantly, it enabled us to being user testing immediately, as well as to identify UI elements that would need to be defined via a style guide. 

<insert drawing > wireframes > screen cap image>

Testing:
Our core team tested features constantly, but we also put our core group of users to work every day testing the latest release. An email was sent to this group every morning outlining what had changed and asking them to test. Later in the day, the user group gathered with the core team to review and prioritize feedback. High priority items were flagged on the project board as "MVP" and remaining items were added to the backlog for later consideration. 

<screen cap of daily user feedback and project board showing feedback translated in to a story>
